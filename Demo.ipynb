{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d12f94-9738-4ff0-be55-50472b2a5e06",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544d979-8096-456b-b57a-819f3378a17a",
   "metadata": {},
   "source": [
    "Какво е deployment? В изолация, всяко парче код е безполезно, включително и ML/AI. Deployment е процесът по \"отваряне\" на кода, така че други системи или потребители да могат да достъпват нашия софтуер.\n",
    "\n",
    "В това демо ние ще:\n",
    "1. Натренираме модел за оценка на sentiment на филмови коментари на български език\n",
    "2. Подготвим web service, който да използва натренирания модел да оценява нови ревюта\n",
    "3. Deploy на дадения web service в облака, за да бъде достъпен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13374622-03fd-4f0a-b195-ed3f94351eda",
   "metadata": {},
   "source": [
    "## Трениране на модел\n",
    "Ще натренираме модел, който използва отворени данни, за да оцени дали дадено ревю за филм е позитивно или негативно (т.нар sentiment). Използваме готов dataset от huggingface - някой се е погрижил да събере ревюта на български и имаме леснодостъпна информация кое е позитивно/негативно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc1b60f-1b1d-4beb-a81f-dbea2c91b50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Невероятен!!! Ако искате да гледате нещо нестандартно, не се двоумете - това е филмът за вас ;))',\n",
       " 'Много добре направен :)',\n",
       " 'Определено най-добрият Хобит!',\n",
       " 'Муден старт, но нататък е хубав, ненатоварващ и приятен!',\n",
       " 'Невероятна поредица.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = \"sepidmnorozy/Bulgarian_sentiment\"\n",
    "ds = load_dataset(dataset, split=\"train\")\n",
    "ds['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac998e2-608a-4f0c-83ca-e88e163a9b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Общо имаме 5412 филмови ревюта (samples)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Позитивните ревюта са 84.76% от всички'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"Общо имаме {len(ds['label'])} филмови ревюта (samples)\")\n",
    "display(f\"Позитивните ревюта са {sum(ds['label'])/len(ds['label'])*100:.2f}% от всички\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecef87-19a0-4e97-8e7c-a4215b54e347",
   "metadata": {},
   "source": [
    "Първо, трябва да превърнем текста в ML-readable формат, тоест във вектор от числа. Процесът по преобразуване на текст в числен вектор се нарича tokenization, като всяко число отговаря на token. Примерно, частицата \"чно\" може да отговаря на числото 346."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b01091-b514-49a1-a41c-a3947b5a6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([348,  31, 102, 229,  97,  12, 311, 159,  28, 165, 116, 135, 139, 116,\n",
       "         107, 184, 107,  67, 221, 286,  39,  25,  70,  71,  95, 136,   4, 214,\n",
       "           2, 164, 116,  18,  32, 115, 142,  61, 216, 114,  83, 178,  23,  36,\n",
       "          36, 347, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349,\n",
       "         349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349,\n",
       "         349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349],\n",
       "        dtype=torch.int32),\n",
       " tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import Tokenizer, TokenizingDataset\n",
    "vocab_size = 350    # number of tokens\n",
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit(ds['text'])\n",
    "train_ds = TokenizingDataset(ds, tokenizer)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec18f3-4f0a-4dec-8793-bec93e241bf3",
   "metadata": {},
   "source": [
    "Тренираме модел. Моделът \"учи\" как изглеждат нашите данни - в случая нашите ревю и какво прави дадено ревю позитивно или негативно. Един научен модел използва \"наученото\", за да оцени нови ревюта, които не е виждал преди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27daab9-e629-4136-8b20-54139bdfce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss=915.8738434910774\n",
      "epoch accuracy: 0.7437176644493718\n",
      "epoch_loss=884.5177562385798\n",
      "epoch accuracy: 0.844789356984479\n",
      "epoch_loss=877.668301448226\n",
      "epoch accuracy: 0.8396156688839616\n",
      "epoch_loss=860.2318843454123\n",
      "epoch accuracy: 0.8423872875092387\n",
      "epoch_loss=898.149313531816\n",
      "epoch accuracy: 0.8451589061345159\n",
      "epoch_loss=888.9187539368868\n",
      "epoch accuracy: 0.8518107908351811\n",
      "epoch_loss=896.4453482367098\n",
      "epoch accuracy: 0.8433111603843311\n",
      "epoch_loss=892.0835991799831\n",
      "epoch accuracy: 0.8534737620103474\n",
      "epoch_loss=909.8101763036102\n",
      "epoch accuracy: 0.8551367331855136\n",
      "epoch_loss=908.8069994170219\n",
      "epoch accuracy: 0.8590169992609017\n",
      "epoch_loss=876.7675055526197\n",
      "epoch accuracy: 0.8584626755358463\n",
      "epoch_loss=913.730321733281\n",
      "epoch accuracy: 0.864560236511456\n",
      "epoch_loss=892.388779072091\n",
      "epoch accuracy: 0.8638211382113821\n",
      "epoch_loss=878.2790558943525\n",
      "epoch accuracy: 0.8680709534368071\n",
      "epoch_loss=858.0687375226989\n",
      "epoch accuracy: 0.8678861788617886\n",
      "epoch_loss=869.3443309804425\n",
      "epoch accuracy: 0.8697339246119734\n",
      "epoch_loss=854.5990651967004\n",
      "epoch accuracy: 0.8691796008869179\n",
      "epoch_loss=840.5265837265179\n",
      "epoch accuracy: 0.8732446415373245\n",
      "epoch_loss=854.1453219959512\n",
      "epoch accuracy: 0.8752771618625277\n",
      "epoch_loss=830.14134094771\n",
      "epoch accuracy: 0.8737989652623799\n"
     ]
    }
   ],
   "source": [
    "from training_procedure import fit_model\n",
    "\n",
    "model = fit_model(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470978e-5455-43cf-b9a4-f18b19b35642",
   "metadata": {},
   "source": [
    "За да не се налага да тренираме всеки път, запазваме нашите тренирани компоненти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754f03ab-9743-425d-89c7-5e08ef6c3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer.save(\"tokenizer.pkl\")\n",
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638f3bd-ad6f-408d-a79c-b0a22ac85946",
   "metadata": {},
   "source": [
    "За да използваме модела:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2db621d-2f78-4803-a23b-ff45759014ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1574,  2.2805]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.IntTensor([[10, 15, 20, 25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b68429-5904-4504-9434-02b4ad5a7589",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Това е когато използваме модел натрениран върху познати данни, за да даде резултати върху данни, които той вижда за първи път. На практика, това е стъпката, която придава стойност на нашия модел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af174cf0-2f42-40fc-a3f6-6bf2673b0dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "class SentimentInference():\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, inp: str):\n",
    "        tokens = self.tokenizer.tokenize(inp)[:self.model.context_size+1]\n",
    "        res = self.model(torch.IntTensor([tokens]))\n",
    "        return res.argmax().item()  # 0 is negative, 1 is positive\n",
    "    \n",
    "    @staticmethod\n",
    "    def load():\n",
    "        m = torch.load(\"model.pt\")\n",
    "        t = Tokenizer.load(\"tokenizer.pkl\")\n",
    "        return SentimentInference(m, t)\n",
    "inference = SentimentInference.load()\n",
    "inference(\"скучен и глупав филм\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e88bc340-c7e0-421a-8a8d-cac8dc650a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(\"филмът беше много готин\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bba60-9d02-4a94-a76d-0f748e5b1e47",
   "metadata": {},
   "source": [
    "## Отваряне на достъпа\n",
    "Следва да пуснем този модел на прод. Нашето решение ще бъде:\n",
    "- в облака\n",
    "- безплатно\n",
    "- достъпно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ff938-a09e-41e7-af68-b45a30816433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from model import SentimentInference\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    text: str\n",
    "    username: str\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "inf = SentimentInference.load()\n",
    "\n",
    "@app.post(\"/sentiment\")\n",
    "async def infer_sentiment(req: Review):\n",
    "    res = inf(req.text)\n",
    "    response = \"negative\" if res == 0 else \"positive\"\n",
    "    return {\"sentiment\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ec67b-70b0-4812-b8b8-feeac902e047",
   "metadata": {},
   "source": [
    "## Отваряне на достъпа\n",
    "Сега ще отворим безплатен сървър, чиято цел ще бъде да \"държи\" нашия модел и да може да отговаря на \"рекуести\". Ще го направим в облака и ще качим на сървъра нашия код, заедно с тренираните ни модели. Ще отворим порт, за да можем да го достъпваме през интернет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94606e9a-fc4c-4860-b566-01d430dec2f5",
   "metadata": {},
   "source": [
    "# Какво липсва в тази презентация?\n",
    "- automated deploy - понякога се налага периодично да тренираме нов модел и той автоматично да се деплойва вместо ръчно да го качваме по всички наши сървъри\n",
    "- security - всеки може да достъпва нашата виртуална машина. Нямаме никаква защита против атака, примерно DDOS\n",
    "- scale - моделът е прост и има само една инстанция. Обикновено се налага да имаме възможност да осигурим повече ресурси\n",
    "- docker и kubernetes - един сървиз би влязъл в контейнер под kubernetes. На практика, няма да се налага да правим ръчните команди по сетване на нова виртуалка, а нашия сървиз би бил по-secure и по-manageable откъм monitoring, logging, automated scaling, etc\n",
    "- stress test - на какъв брой рекуести може да издържи нашия сървиз\n",
    "- monitoring - как да разберем възможно най-бързо когато има проблем със сървиза или AWS\n",
    "- networking - важна тема, но реших да не разводнявам дискусията. Добра идея е поне да фиксираме адреса на нашия сървиз, така че да не го викаме по IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139e8a9-11dd-45a4-bc2f-0bb8b91795b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
