{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d12f94-9738-4ff0-be55-50472b2a5e06",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544d979-8096-456b-b57a-819f3378a17a",
   "metadata": {},
   "source": [
    "Какво е deployment? В изолация, всяко парче код е безполезно, включително и ML/AI. Deployment е процесът по \"отваряне\" на кода, така че други системи или потребители да могат да достъпват нашия софтуер "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13374622-03fd-4f0a-b195-ed3f94351eda",
   "metadata": {},
   "source": [
    "## Трениране на модел\n",
    "Ще натренираме модел, който използва отворен dataset, за да оцени дали дадено ревю за филм е позитивно или негативно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc1b60f-1b1d-4beb-a81f-dbea2c91b50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Невероятен!!! Ако искате да гледате нещо нестандартно, не се двоумете - това е филмът за вас ;))',\n",
       " 'Много добре направен :)',\n",
       " 'Определено най-добрият Хобит!',\n",
       " 'Муден старт, но нататък е хубав, ненатоварващ и приятен!',\n",
       " 'Невероятна поредица.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = \"sepidmnorozy/Bulgarian_sentiment\"\n",
    "ds = load_dataset(dataset, split=\"train\")\n",
    "ds['text'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecef87-19a0-4e97-8e7c-a4215b54e347",
   "metadata": {},
   "source": [
    "Първо, трябва да превърнем текста в ML-readable формат, тоест във вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b01091-b514-49a1-a41c-a3947b5a6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([348,   9, 102, 229,  97,  48, 311, 159,   2, 165, 116, 135, 139, 116,\n",
       "         107, 184, 107,  67, 221, 286,  52,  11,  70,  71,  95, 136,  44, 214,\n",
       "          31, 164, 116,  23,  43, 115, 142,  61, 216, 114,  83, 178,  50,  45,\n",
       "          45, 347, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349,\n",
       "         349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349,\n",
       "         349, 349, 349, 349, 349, 349, 349, 349, 349, 349, 349],\n",
       "        dtype=torch.int32),\n",
       " tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import Tokenizer, TokenizingDataset\n",
    "vocab_size = 350    # number of tokens\n",
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit(ds['text'])\n",
    "train_ds = TokenizingDataset(ds, tokenizer)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec18f3-4f0a-4dec-8793-bec93e241bf3",
   "metadata": {},
   "source": [
    "Тренираме модел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27daab9-e629-4136-8b20-54139bdfce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss=914.6326519995928\n",
      "epoch accuracy: 0.7354028085735402\n",
      "epoch_loss=978.675831027329\n",
      "epoch accuracy: 0.8471914264597191\n",
      "epoch_loss=1023.2758037447929\n",
      "epoch accuracy: 0.8468218773096822\n",
      "epoch_loss=961.9597607664764\n",
      "epoch accuracy: 0.844789356984479\n",
      "epoch_loss=961.1016171090305\n",
      "epoch accuracy: 0.840169992609017\n",
      "epoch_loss=952.2176993377507\n",
      "epoch accuracy: 0.8377679231337768\n",
      "epoch_loss=918.0857241936028\n",
      "epoch accuracy: 0.8379526977087953\n",
      "epoch_loss=937.9692882113159\n",
      "epoch accuracy: 0.8457132298595713\n",
      "epoch_loss=907.4984237905592\n",
      "epoch accuracy: 0.8484848484848485\n",
      "epoch_loss=919.4764760602266\n",
      "epoch accuracy: 0.8519955654101996\n",
      "epoch_loss=907.1320295222104\n",
      "epoch accuracy: 0.8551367331855136\n",
      "epoch_loss=884.2947474662215\n",
      "epoch accuracy: 0.8593865484109386\n",
      "epoch_loss=864.6668815985322\n",
      "epoch accuracy: 0.8630820399113082\n",
      "epoch_loss=888.9133908189833\n",
      "epoch accuracy: 0.8623429416112343\n",
      "epoch_loss=866.0947042088956\n",
      "epoch accuracy: 0.8654841093865484\n",
      "epoch_loss=860.8033702131361\n",
      "epoch accuracy: 0.8708425720620843\n",
      "epoch_loss=856.6300105433911\n",
      "epoch accuracy: 0.8750923872875093\n",
      "epoch_loss=847.9427881464362\n",
      "epoch accuracy: 0.8793422025129343\n",
      "epoch_loss=821.326537951827\n",
      "epoch accuracy: 0.8791574279379157\n",
      "epoch_loss=807.3353608325124\n",
      "epoch accuracy: 0.8826681448632668\n"
     ]
    }
   ],
   "source": [
    "from training_procedure import fit_model\n",
    "model = fit_model(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470978e-5455-43cf-b9a4-f18b19b35642",
   "metadata": {},
   "source": [
    "За да не се налага да тренираме всеки път, запазваме нашите тренирани компоненти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754f03ab-9743-425d-89c7-5e08ef6c3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer.save(\"tokenizer.pkl\")\n",
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638f3bd-ad6f-408d-a79c-b0a22ac85946",
   "metadata": {},
   "source": [
    "За да използваме модела:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2db621d-2f78-4803-a23b-ff45759014ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mIntTensor([[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m]]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "model(torch.IntTensor([[10, 15, 20, 25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b68429-5904-4504-9434-02b4ad5a7589",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af174cf0-2f42-40fc-a3f6-6bf2673b0dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "class SentimentInference():\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, inp: str):\n",
    "        tokens = self.tokenizer.tokenize(inp)[:self.model.context_size+1]\n",
    "        res = self.model(torch.IntTensor([tokens]))\n",
    "        return res.argmax().item()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load():\n",
    "        m = torch.load(\"model.pt\")\n",
    "        t = Tokenizer.load(\"tokenizer.pkl\")\n",
    "        return SentimentInference(m, t)\n",
    "inference = SentimentInference.load()\n",
    "inference(\"скучен и глупав филм\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bba60-9d02-4a94-a76d-0f748e5b1e47",
   "metadata": {},
   "source": [
    "## Отваряне на достъпа\n",
    "Следва да пуснем този модел на прод. Нашето решение ще бъде:\n",
    "- в облака\n",
    "- безплатно\n",
    "- достъпно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94606e9a-fc4c-4860-b566-01d430dec2f5",
   "metadata": {},
   "source": [
    "# Какво липсва в тази презентация?\n",
    "- security - всеки може да достъпва нашата виртуална машина. Нямаме никаква защита против атака, примерно DDOS. Това е отговорна задача и е важно да се следват добри практики. Това е дискусия за друга презентация и от друг презентатор\n",
    "- scale - моделът е прост и има само една инстанция. Обикновено се налага да имаме възможност да осигурим повече ресурси. Тук е също голяма дискусия, но е хубаво да имаме предвид колко трафик е необходимо да издържа - прекалено много неизползвани ресурси са чиста загуба на пари, прекалено малко означава, че няма да имаме сървиз \n",
    "- docker и kubernetes - реших да не усложнявам презентацията, но принципно добрата практика диктува, че нашия сървиз би влязъл в контейнер и би скалирал с kubernetes. На практика, няма да се налага да правим ръчните команди по теглене на репото, а нашия сървиз би бил по-secure и по-manageable откъм monitoring, logging, automated scaling, etc\n",
    "- stress test - на какъв брой рекуести може да издържи нашия сървиз\n",
    "- monitoring - как да разберем възможно най-бързо когато има проблем със сървиза или AWS\n",
    "- networking - важна тема, но реших да не разводнявам дискусията. Добра идея е поне да фиксираме адреса на нашия сървиз, така че да не го викаме по IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b78a51-d68d-4095-81e1-d77f1bc13206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
